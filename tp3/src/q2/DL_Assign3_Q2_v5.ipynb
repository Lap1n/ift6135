{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assign3_Q2_v5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "7ce_sa4D3EtZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import utils\n",
        "import torch.utils.data as data_utils\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.nn.modules import upsampling\n",
        "from torch.functional import F\n",
        "from torch.optim import Adam\n",
        "\n",
        "\n",
        "from torchvision.utils import save_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dBBo24QFGEP4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ueLMu9qF8xIM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# To do this assignment, I did look at this code for the general framework of how to implement VAE and I did copy some code from there:\n",
        "https://github.com/pytorch/examples/blob/master/vae/main.py"
      ]
    },
    {
      "metadata": {
        "id": "rm8up2kW5hzs",
        "colab_type": "code",
        "outputId": "a9f1f4f6-d408-43a6-c97e-3d7539388a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "cell_type": "code",
      "source": [
        "# If a GPU is available, use it\n",
        "# Pytorch uses an elegant way to keep the code device agnostic\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    use_cuda = True\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    use_cuda = False\n",
        "    \n",
        "print(device)\n",
        "\n",
        "#torch.manual_seed(1) # I may need to fix other seeds"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ung8rzlD3OSl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_data_loader(dataset_location, batch_size):\n",
        "    URL = \"http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/\"\n",
        "    # start processing\n",
        "    def lines_to_np_array(lines):\n",
        "        return np.array([[int(i) for i in line.split()] for line in lines])\n",
        "    splitdata = []\n",
        "    for splitname in [\"train\", \"valid\", \"test\"]:\n",
        "        filename = \"binarized_mnist_%s.amat\" % splitname\n",
        "        filepath = os.path.join(dataset_location, filename)\n",
        "        utils.download_url(URL + filename, dataset_location)\n",
        "        with open(filepath) as f:\n",
        "            lines = f.readlines()\n",
        "        x = lines_to_np_array(lines).astype('float32')\n",
        "        x = x.reshape(x.shape[0], 1, 28, 28)\n",
        "        # pytorch data loader\n",
        "        dataset = data_utils.TensorDataset(torch.from_numpy(x))\n",
        "        print(splitname, len(dataset))\n",
        "        dataset_loader = data_utils.DataLoader(x, batch_size=batch_size, shuffle=splitname == \"train\")\n",
        "        splitdata.append(dataset_loader)\n",
        "    return splitdata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CaSQVRRi3MaG",
        "colab_type": "code",
        "outputId": "429c007b-1748-4451-cb02-11744558ab3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train, valid, test = get_data_loader(\"binarized_mnist\", 64)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_train.amat to binarized_mnist/binarized_mnist_train.amat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "78405632it [00:04, 16066498.29it/s]                              \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train 50000\n",
            "Downloading http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_valid.amat to binarized_mnist/binarized_mnist_valid.amat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15687680it [00:02, 6184490.67it/s]                              \n",
            "  0%|          | 0/15680000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "valid 10000\n",
            "Downloading http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_test.amat to binarized_mnist/binarized_mnist_test.amat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15687680it [00:02, 7259398.65it/s]                              \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YjuRoyQ93aGR",
        "colab_type": "code",
        "outputId": "f3d5aa2f-9c19-405e-f44a-4a06d428ac1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "cell_type": "code",
      "source": [
        "print(f\"Your version of Pytorch is {torch.__version__}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your version of Pytorch is 1.0.1.post2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4kghFP-B3gAj",
        "colab_type": "code",
        "outputId": "5ddbeb17-8d95-4b7c-af04-e456b1dd999a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "for x in train:\n",
        "    print(x.shape)\n",
        "    plt.imshow(x[0, 0])\n",
        "    break"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nijJ+qSjjl4oyfqko45eKMn6pqP8CIJbB4Ow6tUAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "nGOBw5ZE3qYC",
        "colab_type": "code",
        "outputId": "30b63d9c-cb07-4160-92ee-d4c973bd0345",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "cell_type": "code",
      "source": [
        "print(train)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f4cdb881710>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WnR1sTruMEpP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Question 2.1: Train a VAE (10pts)"
      ]
    },
    {
      "metadata": {
        "id": "coXuahzZ26WG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Q2_VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Q2_VAE, self).__init__()\n",
        "        self.m = nn.ELU()\n",
        "        self.conv_e1 = nn.Conv2d(1, 32, (3, 3))\n",
        "        # ELU\n",
        "        self.avg_pool_e1 = nn.AvgPool2d(kernel_size = 2, stride=2)\n",
        "        self.conv_e2 = nn.Conv2d(32, 64, (3, 3))\n",
        "        # ELU\n",
        "        self.avg_pool_e2 = nn.AvgPool2d(kernel_size = 2, stride=2)\n",
        "        self.conv_e3 = nn.Conv2d(64, 256, (5, 5))\n",
        "        # ELU\n",
        "        # Ne pas oublier de mettre en ligne les 256 pour faire une couche de MLP\n",
        "        \n",
        "        self.linear_mean = nn.Linear(256, 100, bias=True)\n",
        "        self.linear_log_var = nn.Linear(256, 100, bias=True)\n",
        "        \n",
        "        self.linear_d1 = nn.Linear(100, 256, bias=True)\n",
        "        # ELU\n",
        "        # Je dois augmenter de deux dimensions(inverse de .view())\n",
        "        self.conv_d1 = nn.Conv2d(256, 64, kernel_size=(5, 5), padding=(4, 4))\n",
        "        # ELU\n",
        "        #self.upsamp_d1 =nn.UpsamplingBilinear2d(scale_factor=2, mode='bilinear')\n",
        "        self.conv_d2 = nn.Conv2d(64, 32, kernel_size=(3, 3), padding=(2, 2))\n",
        "        # ELU\n",
        "        #self.upsamp_d2 =nn.UpsamplingBilinear2d(scale_factor=2, mode='bilinear')\n",
        "        self.conv_d3 = nn.Conv2d(32, 16, kernel_size=(3, 3), padding=(2, 2))\n",
        "        # ELU\n",
        "        self.conv_d4 = nn.Conv2d(16, 1, kernel_size=(3, 3), padding=(2, 2))\n",
        "        \n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.conv_e1(x)\n",
        "        x = self.m(x)\n",
        "        x = self.avg_pool_e1(x)\n",
        "        #print(\"Ici: \", x.shape)\n",
        "        x = self.conv_e2(x)\n",
        "        x = self.m(x)\n",
        "        x = self.avg_pool_e2(x)\n",
        "        x = self.conv_e3(x)\n",
        "        x = self.m(x)\n",
        "        x = x.view(-1, 256) \n",
        "        return self.linear_mean(x), self.linear_log_var(x)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar) + 10**(-7)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "    def decode(self, z):\n",
        "        out = self.linear_d1(z)\n",
        "        out = self.m(out)\n",
        "        out = out.view(-1, 256, 1, 1) # LFPR: J'ai change ca aussi\n",
        "        out = self.conv_d1(out)\n",
        "        out = self.m(out)\n",
        "        #out = self.upsamp_d1(out)\n",
        "        out = F.interpolate(out, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        out = self.conv_d2(out)\n",
        "        out = self.m(out)\n",
        "        #out = self.upsamp_d2(out)\n",
        "        out = F.interpolate(out, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        out = self.conv_d3(out)\n",
        "        out = self.m(out)\n",
        "        return self.conv_d4(out)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        #mu, logvar = self.encode(x.view(-1, 784))\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xueR_J-S7_H8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reconstruction + KL divergence losses summed over all elements and batch\n",
        "# We return the negative of the ELBO for gradient descent\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    \n",
        "    BCE=-torch.sum(F.binary_cross_entropy(torch.sigmoid(recon_x.view(-1, 784)\\\n",
        "                          ), x.view(-1, 784), reduction='none'),dim=1).mean()\n",
        "    \n",
        "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD = 0.5*torch.sum(-1 - logvar + mu.pow(2) + logvar.exp(), dim = 1).mean()\n",
        "\n",
        "    #return BCE + KLD\n",
        "    return - (BCE - KLD)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_VAE(epoch,loader):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    #for batch_idx, (data, _) in enumerate(loader):\n",
        "    for batch_idx, data in enumerate(loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        loss = loss_function(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        #if batch_idx % 100 == 0:\n",
        "        #    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t average ELBO: {:.6f}'.format(\n",
        "        #        epoch, batch_idx * len(data), len(loader.dataset),\n",
        "        #        100. * batch_idx / len(loader),\n",
        "        #        - batch_size * loss.item() / len(data)))\n",
        "        \n",
        "    average_ELBO = - train_loss * batch_size / len(loader.dataset)\n",
        "    print('====> Epoch: {} Train set average ELBO: {:.4f}'.format(\n",
        "          epoch, average_ELBO))\n",
        "    return average_ELBO\n",
        "\n",
        "\n",
        "def test_VAE(epoch, loader, state = \"Validation\"):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        #for i, (data, _) in enumerate(loader):\n",
        "        for i, data in enumerate(loader):\n",
        "            data = data.to(device)\n",
        "            recon_batch, mu, logvar = model(data)\n",
        "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
        "            #if i == 0:\n",
        "            #    n = min(data.size(0), 8)\n",
        "            #    comparison = torch.cat([data[:n],\n",
        "            #                            recon_batch.view(batch_size, 1, 28, 28)[:n]])\n",
        "            #    save_image(comparison.cpu(),\n",
        "            #                str(epoch) + '.png', nrow=n)\n",
        "    \n",
        "    test_loss /= (len(loader.dataset)/ batch_size)\n",
        "    average_ELBO = - test_loss\n",
        "    print('====> ' + state +' set average ELBO: {:.4f}'.format(average_ELBO))\n",
        "    return average_ELBO\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qM0-aEfYZ6DI",
        "colab_type": "code",
        "outputId": "6b061aee-4e8f-40ca-e6ec-90e29d9c8ff0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "cell_type": "code",
      "source": [
        "len(train.dataset)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "IWgQ_CEQZ-mJ",
        "colab_type": "code",
        "outputId": "a08fb209-7763-4b5f-c15f-077015668821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "cell_type": "code",
      "source": [
        "model = Q2_VAE()\n",
        "model = model.to(device)\n",
        "\n",
        "#optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "optimizer = Adam(model.parameters(), lr=3 * 10**(-4))\n",
        "\n",
        "\n",
        "print(model)\n",
        "print(\"\\n\\n# Parameters: \", sum([param.nelement() for param in model.parameters()]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q2_VAE(\n",
            "  (m): ELU(alpha=1.0)\n",
            "  (conv_e1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (avg_pool_e1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (conv_e2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (avg_pool_e2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (conv_e3): Conv2d(64, 256, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (linear_mean): Linear(in_features=256, out_features=100, bias=True)\n",
            "  (linear_log_var): Linear(in_features=256, out_features=100, bias=True)\n",
            "  (linear_d1): Linear(in_features=100, out_features=256, bias=True)\n",
            "  (conv_d1): Conv2d(256, 64, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4))\n",
            "  (conv_d2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "  (conv_d3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "  (conv_d4): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            ")\n",
            "\n",
            "\n",
            "# Parameters:  938825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NrM2xuFyZ-vS",
        "colab_type": "code",
        "outputId": "98ab479c-ce3b-41e3-b5e6-6b6171cea0e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 876
        }
      },
      "cell_type": "code",
      "source": [
        "nb_epochs = 20\n",
        "for epoch in range(1, nb_epochs + 1):\n",
        "    train_VAE(epoch, train)\n",
        "    test_VAE(epoch, valid)\n",
        "    #with torch.no_grad():\n",
        "    #    sample = torch.randn(64, 100).to(device)\n",
        "    #    sample = model.decode(sample).cpu()\n",
        "    #    save_image(sample.view(64, 1, 28, 28),\n",
        "    #                str(epoch) + '.png')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====> Epoch: 1 Train set average ELBO: -185.5547\n",
            "====> Validation set average ELBO: -138.8882\n",
            "====> Epoch: 2 Train set average ELBO: -125.8673\n",
            "====> Validation set average ELBO: -118.1424\n",
            "====> Epoch: 3 Train set average ELBO: -112.8544\n",
            "====> Validation set average ELBO: -110.1464\n",
            "====> Epoch: 4 Train set average ELBO: -107.2846\n",
            "====> Validation set average ELBO: -106.1305\n",
            "====> Epoch: 5 Train set average ELBO: -104.1493\n",
            "====> Validation set average ELBO: -104.2705\n",
            "====> Epoch: 6 Train set average ELBO: -102.0333\n",
            "====> Validation set average ELBO: -102.3650\n",
            "====> Epoch: 7 Train set average ELBO: -100.5472\n",
            "====> Validation set average ELBO: -100.5575\n",
            "====> Epoch: 8 Train set average ELBO: -99.3786\n",
            "====> Validation set average ELBO: -99.9093\n",
            "====> Epoch: 9 Train set average ELBO: -98.5169\n",
            "====> Validation set average ELBO: -98.6123\n",
            "====> Epoch: 10 Train set average ELBO: -97.6760\n",
            "====> Validation set average ELBO: -98.1627\n",
            "====> Epoch: 11 Train set average ELBO: -97.0711\n",
            "====> Validation set average ELBO: -97.5136\n",
            "====> Epoch: 12 Train set average ELBO: -96.4673\n",
            "====> Validation set average ELBO: -96.9320\n",
            "====> Epoch: 13 Train set average ELBO: -96.0252\n",
            "====> Validation set average ELBO: -96.5599\n",
            "====> Epoch: 14 Train set average ELBO: -95.5726\n",
            "====> Validation set average ELBO: -96.0889\n",
            "====> Epoch: 15 Train set average ELBO: -95.2271\n",
            "====> Validation set average ELBO: -95.9021\n",
            "====> Epoch: 16 Train set average ELBO: -94.8910\n",
            "====> Validation set average ELBO: -95.4961\n",
            "====> Epoch: 17 Train set average ELBO: -94.5513\n",
            "====> Validation set average ELBO: -95.5399\n",
            "====> Epoch: 18 Train set average ELBO: -94.3059\n",
            "====> Validation set average ELBO: -94.8717\n",
            "====> Epoch: 19 Train set average ELBO: -94.0111\n",
            "====> Validation set average ELBO: -94.7403\n",
            "====> Epoch: 20 Train set average ELBO: -93.8175\n",
            "====> Validation set average ELBO: -94.6678\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DK0YUfHDNPTJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**As can be seen in the previous cell, we obtain an ELBO more than -96 on the validation set after 20 epochs.**"
      ]
    },
    {
      "metadata": {
        "id": "GMQeQS1bMQqq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Question 2.2: Evaluating log-likelihood with Variational Autoencoders (20 pts)"
      ]
    },
    {
      "metadata": {
        "id": "mobnEBqDMYOK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 2.2.1**"
      ]
    },
    {
      "metadata": {
        "id": "N_2Pldyd58XT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def copy_tensor_K_times(tensor, K):\n",
        "  return torch.stack([tensor.clone() for _ in range(K)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uxJjrSgr8lWl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reconstruction(multi_x,z_x,model):\n",
        "  recon_x = model.decode(z_x)\n",
        "  return - torch.sum(F.binary_cross_entropy(torch.sigmoid(recon_x.view(-1, 784)), multi_x.view(-1, 784), reduction='none'),dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4lQ7fIE064UB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def log_gaussian_standard(z):\n",
        "  # no more terms because mu = 0 and sigma = 1\n",
        "  L = z.shape[1]\n",
        "  pi_term = - (L/2) * torch.log(torch.tensor(2 * math.pi))\n",
        "  return torch.sum(- z**2/2, dim = 1) + pi_term"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V7QDQLKk8WGV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def log_gaussian_density(z_x, multi_x, model):\n",
        "  mu, logvar = model.encode(multi_x)\n",
        "  L = z_x.shape[1]\n",
        "  pi_term = - (L/2) * torch.log(torch.tensor(2 * math.pi))\n",
        "  # We add 10**(-7) to avoid taking the log of 0 if logvar is very negative\n",
        "  return torch.sum(-(z_x - mu)**2/(2*torch.exp(logvar)+ 10**(-7)) - torch.log(torch.exp(0.5*logvar) + 10**(-7)), dim = 1) + pi_term"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S-DTHCpiMNHY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def importance_sampling(model, X, Z):\n",
        "  X = X.view((-1,1,28,28))\n",
        "  model.eval()\n",
        "  log_probs = []\n",
        "  for pos, x in enumerate(X):\n",
        "    z_x = Z[pos]\n",
        "    multi_x = copy_tensor_K_times(x, Z.shape[1]) \n",
        "    log_p_x_z = reconstruction(multi_x,z_x,model)\n",
        "    log_p_z = log_gaussian_standard(z_x)\n",
        "    log_q_z_x = log_gaussian_density(z_x, multi_x, model)\n",
        "    w =log_p_x_z + log_p_z - log_q_z_x\n",
        "    m = torch.max(w)\n",
        "    value = - torch.log(torch.tensor(Z.shape[1],dtype=torch.float64)) + m + torch.log(torch.sum(torch.exp(w-m)))\n",
        "    log_probs.append(value)\n",
        "  return log_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CnXmdniv11Ir",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 2.2.2**"
      ]
    },
    {
      "metadata": {
        "id": "oL4jqlpnMXev",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def all_log_X(model,loader,K):\n",
        "  model.eval()\n",
        "  les_log_probs = []\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, data in enumerate(loader):\n",
        "      data = data.to(device)\n",
        "      for x in data:\n",
        "        multi_x = copy_tensor_K_times(x, K)\n",
        "        mu, log_var = model.encode(multi_x)\n",
        "        z = model.reparameterize(mu, log_var)\n",
        "        les_log_probs += importance_sampling(model, x.view((1,784)), z[None, : ,:])\n",
        "  return les_log_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4qGn0zsAgkM2",
        "colab_type": "code",
        "outputId": "eb3814ff-7397-4242-d4ce-cff196751c4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "cell_type": "code",
      "source": [
        "model = Q2_VAE()\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=3 * 10**(-4))\n",
        "\n",
        "print(model)\n",
        "print(\"\\n\\n# Parameters: \", sum([param.nelement() for param in model.parameters()]))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q2_VAE(\n",
            "  (m): ELU(alpha=1.0)\n",
            "  (conv_e1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (avg_pool_e1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (conv_e2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (avg_pool_e2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (conv_e3): Conv2d(64, 256, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (linear_mean): Linear(in_features=256, out_features=100, bias=True)\n",
            "  (linear_log_var): Linear(in_features=256, out_features=100, bias=True)\n",
            "  (linear_d1): Linear(in_features=100, out_features=256, bias=True)\n",
            "  (conv_d1): Conv2d(256, 64, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4))\n",
            "  (conv_d2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "  (conv_d3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "  (conv_d4): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            ")\n",
            "\n",
            "\n",
            "# Parameters:  938825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BtvyuutNz04O",
        "colab_type": "code",
        "outputId": "1ad827fd-99d3-42d2-e8a5-1da16209b268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1128
        }
      },
      "cell_type": "code",
      "source": [
        "nb_epochs = 20\n",
        "valid_ELBOs = []\n",
        "test_ELBOs = []\n",
        "log_likeli_est_valid = []\n",
        "log_likeli_est_test = []\n",
        "for epoch in range(1, nb_epochs + 1):\n",
        "    train_VAE(epoch, train)\n",
        "    test_VAE(epoch, valid, \"Validation\")\n",
        "    test_VAE(epoch, test, \"Test\")\n",
        "    \n",
        "    #with torch.no_grad():\n",
        "    #    sample = torch.randn(64, 100).to(device)\n",
        "    #    sample = model.decode(sample).cpu()\n",
        "    #    save_image(sample.view(64, 1, 28, 28),\n",
        "    #                str(epoch) + '.png')\n",
        "    \n",
        "v_log_like_est= torch.stack(all_log_X(model,valid,200)).mean()\n",
        "print(\"valid log likelihood estimate: \", v_log_like_est.item())\n",
        "\n",
        "t_log_like_est= torch.stack(all_log_X(model,test,200)).mean()\n",
        "print(\"test log likelihood estimate: \", t_log_like_est.item())"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====> Epoch: 1 Train set average ELBO: -182.2086\n",
            "====> Validation set average ELBO: -137.4798\n",
            "====> Test set average ELBO: -136.2863\n",
            "====> Epoch: 2 Train set average ELBO: -124.6810\n",
            "====> Validation set average ELBO: -117.2516\n",
            "====> Test set average ELBO: -115.8346\n",
            "====> Epoch: 3 Train set average ELBO: -112.3146\n",
            "====> Validation set average ELBO: -110.0185\n",
            "====> Test set average ELBO: -108.7687\n",
            "====> Epoch: 4 Train set average ELBO: -107.0473\n",
            "====> Validation set average ELBO: -105.8029\n",
            "====> Test set average ELBO: -104.7535\n",
            "====> Epoch: 5 Train set average ELBO: -104.0098\n",
            "====> Validation set average ELBO: -103.7493\n",
            "====> Test set average ELBO: -102.6150\n",
            "====> Epoch: 6 Train set average ELBO: -102.1050\n",
            "====> Validation set average ELBO: -102.0620\n",
            "====> Test set average ELBO: -100.9900\n",
            "====> Epoch: 7 Train set average ELBO: -100.7643\n",
            "====> Validation set average ELBO: -101.2423\n",
            "====> Test set average ELBO: -100.1778\n",
            "====> Epoch: 8 Train set average ELBO: -99.6615\n",
            "====> Validation set average ELBO: -99.7948\n",
            "====> Test set average ELBO: -98.7674\n",
            "====> Epoch: 9 Train set average ELBO: -98.7019\n",
            "====> Validation set average ELBO: -99.0343\n",
            "====> Test set average ELBO: -98.0743\n",
            "====> Epoch: 10 Train set average ELBO: -97.9935\n",
            "====> Validation set average ELBO: -98.3741\n",
            "====> Test set average ELBO: -97.3753\n",
            "====> Epoch: 11 Train set average ELBO: -97.3863\n",
            "====> Validation set average ELBO: -98.2996\n",
            "====> Test set average ELBO: -97.2373\n",
            "====> Epoch: 12 Train set average ELBO: -96.8562\n",
            "====> Validation set average ELBO: -97.6427\n",
            "====> Test set average ELBO: -96.7659\n",
            "====> Epoch: 13 Train set average ELBO: -96.3763\n",
            "====> Validation set average ELBO: -97.0725\n",
            "====> Test set average ELBO: -96.1737\n",
            "====> Epoch: 14 Train set average ELBO: -95.8662\n",
            "====> Validation set average ELBO: -96.6772\n",
            "====> Test set average ELBO: -95.8616\n",
            "====> Epoch: 15 Train set average ELBO: -95.5729\n",
            "====> Validation set average ELBO: -96.2524\n",
            "====> Test set average ELBO: -95.5237\n",
            "====> Epoch: 16 Train set average ELBO: -95.1894\n",
            "====> Validation set average ELBO: -96.2305\n",
            "====> Test set average ELBO: -95.3623\n",
            "====> Epoch: 17 Train set average ELBO: -94.8945\n",
            "====> Validation set average ELBO: -95.9322\n",
            "====> Test set average ELBO: -95.0785\n",
            "====> Epoch: 18 Train set average ELBO: -94.5468\n",
            "====> Validation set average ELBO: -95.4166\n",
            "====> Test set average ELBO: -94.5276\n",
            "====> Epoch: 19 Train set average ELBO: -94.2970\n",
            "====> Validation set average ELBO: -95.6207\n",
            "====> Test set average ELBO: -94.8857\n",
            "====> Epoch: 20 Train set average ELBO: -94.0971\n",
            "====> Validation set average ELBO: -95.3463\n",
            "====> Test set average ELBO: -94.6471\n",
            "valid log likelihood estimate:  -89.25230812297677\n",
            "test log likelihood estimate:  -88.60751239174044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wI9QyaWhf9vJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**As can be seen in the results above, after training the model with 20 epochs, we obtain:**\n",
        "\n",
        "- **the ELBO on the validation set  is given by -95.3463**\n",
        "\n",
        "- **the ELBO on the test set  is given by -94.6471**\n",
        "\n",
        "- **the log-likelihood  estimate  on the validation set is given by -89.25230812297677**\n",
        "\n",
        "- **the log-likelihood  estimate  on the test set is given by -88.60751239174044**\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "L4Lj7wcNN7pa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "09995092-e4a1-4162-bc28-9b8e177f281b"
      },
      "cell_type": "code",
      "source": [
        "# This is just to verify that the method importance_sampling(model, X, Z)\n",
        "# accepts:\n",
        "#\n",
        "# a model \n",
        "# An (M,D) array of xi’s\n",
        "# An (M,K,L) array of zik’s\n",
        "#\n",
        "# returns\n",
        "# (logp(x1),...,logp(xM)) estimates of size (M,)\n",
        "\n",
        "K = 200\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for batch_idx, data in enumerate(train):\n",
        "    data = data.to(device)\n",
        "    count = 0\n",
        "    les_x = []\n",
        "    les_z = []\n",
        "    for x in data:\n",
        "      count+=1\n",
        "      multi_x = copy_tensor_K_times(x, K)\n",
        "      mu, log_var = model.encode(multi_x)\n",
        "      z = model.reparameterize(mu, log_var)\n",
        "      les_x.append(x.view((784)))\n",
        "      les_z.append(z[: ,:])\n",
        "      if count == 5:\n",
        "        les_x = torch.stack(les_x)\n",
        "        les_z = torch.stack(les_z)\n",
        "        break\n",
        "    break\n",
        "print(torch.stack(importance_sampling(model,les_x,les_z)).detach().numpy())"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-114.86806076 -113.00088173  -77.9582284   -77.7466666   -94.3350673 ]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}