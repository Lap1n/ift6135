{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assign3_Q2_v4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "7ce_sa4D3EtZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import utils\n",
        "import torch.utils.data as data_utils\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.nn.modules import upsampling\n",
        "from torch.functional import F\n",
        "from torch.optim import Adam\n",
        "\n",
        "\n",
        "from torchvision.utils import save_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ueLMu9qF8xIM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# To do this assignment, I did look at this code for the general framework of how to implement VAE and I did copy some code from there:\n",
        "https://github.com/pytorch/examples/blob/master/vae/main.py"
      ]
    },
    {
      "metadata": {
        "id": "rm8up2kW5hzs",
        "colab_type": "code",
        "outputId": "baa5e554-b5c7-478c-b606-68bb1280509f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        }
      },
      "cell_type": "code",
      "source": [
        "# If a GPU is available, use it\n",
        "# Pytorch uses an elegant way to keep the code device agnostic\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    use_cuda = True\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    use_cuda = False\n",
        "    \n",
        "print(device)\n",
        "\n",
        "#torch.manual_seed(1) # I may need to fix other seeds"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ung8rzlD3OSl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_data_loader(dataset_location, batch_size):\n",
        "    URL = \"http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/\"\n",
        "    # start processing\n",
        "    def lines_to_np_array(lines):\n",
        "        return np.array([[int(i) for i in line.split()] for line in lines])\n",
        "    splitdata = []\n",
        "    for splitname in [\"train\", \"valid\", \"test\"]:\n",
        "        filename = \"binarized_mnist_%s.amat\" % splitname\n",
        "        filepath = os.path.join(dataset_location, filename)\n",
        "        utils.download_url(URL + filename, dataset_location)\n",
        "        with open(filepath) as f:\n",
        "            lines = f.readlines()\n",
        "        x = lines_to_np_array(lines).astype('float32')\n",
        "        x = x.reshape(x.shape[0], 1, 28, 28)\n",
        "        # pytorch data loader\n",
        "        dataset = data_utils.TensorDataset(torch.from_numpy(x))\n",
        "        print(splitname, len(dataset))\n",
        "        dataset_loader = data_utils.DataLoader(x, batch_size=batch_size, shuffle=splitname == \"train\")\n",
        "        splitdata.append(dataset_loader)\n",
        "    return splitdata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CaSQVRRi3MaG",
        "colab_type": "code",
        "outputId": "09063d62-566d-4f0b-c94b-dbf10f3cbc46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train, valid, test = get_data_loader(\"binarized_mnist\", 64)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: binarized_mnist/binarized_mnist_train.amat\n",
            "train 50000\n",
            "Using downloaded and verified file: binarized_mnist/binarized_mnist_valid.amat\n",
            "valid 10000\n",
            "Using downloaded and verified file: binarized_mnist/binarized_mnist_test.amat\n",
            "test 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YjuRoyQ93aGR",
        "colab_type": "code",
        "outputId": "da79fd06-bb7d-4c31-afa0-91fe2ff2eb78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        }
      },
      "cell_type": "code",
      "source": [
        "print(f\"Your version of Pytorch is {torch.__version__}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your version of Pytorch is 1.0.1.post2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4kghFP-B3gAj",
        "colab_type": "code",
        "outputId": "841311f3-093e-4999-87ed-f85d956e46bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "for x in train:\n",
        "    plt.imshow(x[0, 0])\n",
        "    break"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npaYMv9TU/wO4msjYXCEaJAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "nGOBw5ZE3qYC",
        "colab_type": "code",
        "outputId": "0f70674d-e816-4c8f-aaa0-e5829b4783e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        }
      },
      "cell_type": "code",
      "source": [
        "print(train)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f3fef7d8278>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WnR1sTruMEpP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Question 2.1: Train a VAE (10pts)"
      ]
    },
    {
      "metadata": {
        "id": "coXuahzZ26WG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Q2_VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Q2_VAE, self).__init__()\n",
        "        self.m = nn.ELU()\n",
        "        self.conv_e1 = nn.Conv2d(1, 32, (3, 3))\n",
        "        # ELU\n",
        "        self.avg_pool_e1 = nn.AvgPool2d(kernel_size = 2, stride=2)\n",
        "        self.conv_e2 = nn.Conv2d(32, 64, (3, 3))\n",
        "        # ELU\n",
        "        self.avg_pool_e2 = nn.AvgPool2d(kernel_size = 2, stride=2)\n",
        "        self.conv_e3 = nn.Conv2d(64, 256, (5, 5))\n",
        "        # ELU\n",
        "        # Ne pas oublier de mettre en ligne les 256 pour faire une couche de MLP\n",
        "        \n",
        "        self.linear_mean = nn.Linear(256, 100, bias=True)\n",
        "        self.linear_log_var = nn.Linear(256, 100, bias=True)\n",
        "        \n",
        "        self.linear_d1 = nn.Linear(100, 256, bias=True)\n",
        "        # ELU\n",
        "        # Je dois augmenter de deux dimensions(inverse de .view())\n",
        "        self.conv_d1 = nn.Conv2d(256, 64, kernel_size=(5, 5), padding=(4, 4))\n",
        "        # ELU\n",
        "        #self.upsamp_d1 =nn.UpsamplingBilinear2d(scale_factor=2, mode='bilinear')\n",
        "        self.conv_d2 = nn.Conv2d(64, 32, kernel_size=(3, 3), padding=(2, 2))\n",
        "        # ELU\n",
        "        #self.upsamp_d2 =nn.UpsamplingBilinear2d(scale_factor=2, mode='bilinear')\n",
        "        self.conv_d3 = nn.Conv2d(32, 16, kernel_size=(3, 3), padding=(2, 2))\n",
        "        # ELU\n",
        "        self.conv_d4 = nn.Conv2d(16, 1, kernel_size=(3, 3), padding=(2, 2))\n",
        "        \n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.conv_e1(x)\n",
        "        x = self.m(x)\n",
        "        x = self.avg_pool_e1(x)\n",
        "        #print(\"Ici: \", x.shape)\n",
        "        x = self.conv_e2(x)\n",
        "        x = self.m(x)\n",
        "        x = self.avg_pool_e2(x)\n",
        "        x = self.conv_e3(x)\n",
        "        x = self.m(x)\n",
        "        x = x.view(-1, 256) \n",
        "        return self.linear_mean(x), self.linear_log_var(x)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar) + 10**(-7)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "    def decode(self, z):\n",
        "        out = self.linear_d1(z)\n",
        "        out = self.m(out)\n",
        "        out = out.view(-1, 256, 1, 1) # LFPR: J'ai change ca aussi\n",
        "        out = self.conv_d1(out)\n",
        "        out = self.m(out)\n",
        "        #out = self.upsamp_d1(out)\n",
        "        out = F.interpolate(out, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        out = self.conv_d2(out)\n",
        "        out = self.m(out)\n",
        "        #out = self.upsamp_d2(out)\n",
        "        out = F.interpolate(out, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        out = self.conv_d3(out)\n",
        "        out = self.m(out)\n",
        "        return self.conv_d4(out)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        #mu, logvar = self.encode(x.view(-1, 784))\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xueR_J-S7_H8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reconstruction + KL divergence losses summed over all elements and batch\n",
        "# We return the negative of the ELBO for gradient descent\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    \n",
        "    BCE=-torch.sum(F.binary_cross_entropy(torch.sigmoid(recon_x.view(-1, 784)\\\n",
        "                          ), x.view(-1, 784), reduction='none'),dim=1).mean()\n",
        "    \n",
        "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD = 0.5*torch.sum(-1 - logvar + mu.pow(2) + logvar.exp(), dim = 1).mean()\n",
        "\n",
        "    #return BCE + KLD\n",
        "    return - (BCE - KLD)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_VAE(epoch,loader):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    #for batch_idx, (data, _) in enumerate(loader):\n",
        "    for batch_idx, data in enumerate(loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        loss = loss_function(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        #if batch_idx % 100 == 0:\n",
        "        #    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t average ELBO: {:.6f}'.format(\n",
        "        #        epoch, batch_idx * len(data), len(loader.dataset),\n",
        "        #        100. * batch_idx / len(loader),\n",
        "        #        - batch_size * loss.item() / len(data)))\n",
        "        \n",
        "    average_ELBO = - train_loss * batch_size / len(loader.dataset)\n",
        "    print('====> Epoch: {} Train set average ELBO: {:.4f}'.format(\n",
        "          epoch, average_ELBO))\n",
        "    return average_ELBO\n",
        "\n",
        "\n",
        "def test_VAE(epoch, loader, state = \"Validation\"):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        #for i, (data, _) in enumerate(loader):\n",
        "        for i, data in enumerate(loader):\n",
        "            data = data.to(device)\n",
        "            recon_batch, mu, logvar = model(data)\n",
        "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
        "            #if i == 0:\n",
        "            #    n = min(data.size(0), 8)\n",
        "            #    comparison = torch.cat([data[:n],\n",
        "            #                            recon_batch.view(batch_size, 1, 28, 28)[:n]])\n",
        "            #    save_image(comparison.cpu(),\n",
        "            #                str(epoch) + '.png', nrow=n)\n",
        "    \n",
        "    test_loss /= (len(loader.dataset)/ batch_size)\n",
        "    average_ELBO = - test_loss\n",
        "    print('====> ' + state +' set average ELBO: {:.4f}'.format(average_ELBO))\n",
        "    return average_ELBO\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qM0-aEfYZ6DI",
        "colab_type": "code",
        "outputId": "743fb19b-f031-41f4-984f-161ec8c772ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        }
      },
      "cell_type": "code",
      "source": [
        "len(train.dataset)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "IWgQ_CEQZ-mJ",
        "colab_type": "code",
        "outputId": "637ca51b-84bc-4425-f293-dc3c5bbf4d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        }
      },
      "cell_type": "code",
      "source": [
        "model = Q2_VAE()\n",
        "model = model.to(device)\n",
        "\n",
        "#optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "optimizer = Adam(model.parameters(), lr=3 * 10**(-4))\n",
        "\n",
        "\n",
        "print(model)\n",
        "print(\"\\n\\n# Parameters: \", sum([param.nelement() for param in model.parameters()]))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q2_VAE(\n",
            "  (m): ELU(alpha=1.0)\n",
            "  (conv_e1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (avg_pool_e1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (conv_e2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (avg_pool_e2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (conv_e3): Conv2d(64, 256, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (linear_mean): Linear(in_features=256, out_features=100, bias=True)\n",
            "  (linear_log_var): Linear(in_features=256, out_features=100, bias=True)\n",
            "  (linear_d1): Linear(in_features=100, out_features=256, bias=True)\n",
            "  (conv_d1): Conv2d(256, 64, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4))\n",
            "  (conv_d2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "  (conv_d3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "  (conv_d4): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            ")\n",
            "\n",
            "\n",
            "# Parameters:  938825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NrM2xuFyZ-vS",
        "colab_type": "code",
        "outputId": "f863dba0-e7c8-4e22-f601-ead9ce646e87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "cell_type": "code",
      "source": [
        "nb_epochs = 20\n",
        "for epoch in range(1, nb_epochs + 1):\n",
        "    train_VAE(epoch, train)\n",
        "    test_VAE(epoch, valid)\n",
        "    #with torch.no_grad():\n",
        "    #    sample = torch.randn(64, 100).to(device)\n",
        "    #    sample = model.decode(sample).cpu()\n",
        "    #    save_image(sample.view(64, 1, 28, 28),\n",
        "    #                str(epoch) + '.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====> Epoch: 1 Train set average ELBO: -183.5228\n",
            "====> Validation set average ELBO: -138.4655\n",
            "====> Epoch: 2 Train set average ELBO: -126.0273\n",
            "====> Validation set average ELBO: -118.3038\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-91168bbe77f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnb_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_VAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest_VAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#with torch.no_grad():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-b73da440e9a1>\u001b[0m in \u001b[0;36mtrain_VAE\u001b[0;34m(epoch, loader)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#if batch_idx % 100 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "DK0YUfHDNPTJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As can be seen in the previous cell, we obtain an ELBO of more than -95 on the validation set after 20 epochs, which is more than -96"
      ]
    },
    {
      "metadata": {
        "id": "IOzHuQRDNOqv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C6NyxpaZCq1R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " #a = torch.tensor([[-0.5,0.5,0.5],[0.5,0.5,0.5]], dtype=torch.float64)\n",
        " #b = torch.tensor([[1,1,1],[0,0,0]], dtype=torch.float64)\n",
        " #print(torch.sum(F.binary_cross_entropy(a, b, reduction='none')+0,dim = 1))\n",
        " #\n",
        " #print(F.binary_cross_entropy(a, b) * 6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pvjq0wxRajfM",
        "colab_type": "code",
        "outputId": "43aeba65-b0cb-49ff-8c93-cb1582bc245a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[0.5,0.5,0.5],[0.5,0.5,0.5]], dtype=torch.float64)\n",
        "b = torch.tensor([[1,1,1],[0,0,0]], dtype=torch.float64)\n",
        "print(torch.sum(F.binary_cross_entropy(a, b, reduction='none')+0,dim = 1))\n",
        " \n",
        "print(F.binary_cross_entropy(a, b) * 6)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2.0794, 2.0794], dtype=torch.float64)\n",
            "tensor(4.1589, dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GMQeQS1bMQqq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Question 2.2: Evaluating log-likelihood with Variational Autoencoders (20 pts)"
      ]
    },
    {
      "metadata": {
        "id": "mobnEBqDMYOK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 2.2.1**"
      ]
    },
    {
      "metadata": {
        "id": "N_2Pldyd58XT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def copy_tensor_K_times(tensor, K):\n",
        "  return torch.stack([tensor for _ in range(K)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uxJjrSgr8lWl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reconstruction(multi_x,z_x,model):\n",
        "  recon_x = model.decode(z_x)\n",
        "  return - torch.sum(F.binary_cross_entropy(torch.sigmoid(recon_x.view(-1, 784)), multi_x.view(-1, 784), reduction='none'),dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4lQ7fIE064UB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def log_gaussian_standard(z):\n",
        "  return torch.sum(- z**2/2, dim = 1) # pas d'autres termes car sigma = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V7QDQLKk8WGV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def log_gaussian_density(z_x, multi_x, model):\n",
        "  mu, logvar = model.encode(multi_x)\n",
        "  #CONTINUER ICI\n",
        "  return torch.sum(-(z_x - mu)**2/(2*torch.exp(logvar)) - torch.log(torch.exp(0.5*logvar) + 10**(-7)), dim = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S-DTHCpiMNHY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def importance_sampling(model, X, Z):\n",
        "  model.eval()\n",
        "  log_probs = []\n",
        "  for pos, x in enumerate(X):\n",
        "    z_x = Z[pos]\n",
        "    multi_x = copy_tensor_K_times(x, Z.shape[1]) \n",
        "    log_p_x_z = reconstruction(multi_x,z_x,model)\n",
        "    log_p_z = log_gaussian_standard(z_x)\n",
        "    log_q_z_x = log_gaussian_density(z_x, multi_x, model)\n",
        "    #print(\"log_p_x_z \", log_p_x_z)\n",
        "    #print(\"log_p_z \", log_p_z)\n",
        "    #print(\"log_q_z_x \", log_q_z_x)\n",
        "    \n",
        "    w =log_p_x_z + log_p_z - log_q_z_x\n",
        "    #print(w)\n",
        "    m = torch.max(w)\n",
        "    #print(\"max\",m)\n",
        "    #print(w-m)\n",
        "    value = - torch.log(torch.tensor(Z.shape[1],dtype=torch.float64)) + m + torch.log(torch.sum(torch.exp(w-m)))\n",
        "    #print(value)\n",
        "    log_probs.append(value)\n",
        "  return log_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CnXmdniv11Ir",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 2.2.2**"
      ]
    },
    {
      "metadata": {
        "id": "oL4jqlpnMXev",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def all_log_X(model,loader,K):\n",
        "  model.eval()\n",
        "  les_log_probs = []\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, data in enumerate(loader):\n",
        "      data = data.to(device)\n",
        "      #print(data.shape)\n",
        "      for x in data:\n",
        "        multi_x = copy_tensor_K_times(x, K)\n",
        "        mu, log_var = model.encode(multi_x)\n",
        "        z = model.reparameterize(mu, log_var)\n",
        "        #print(x[None, : ,:, :].shape, z.shape)\n",
        "        les_log_probs += importance_sampling(model, x[None, : ,:, :], z[None, : ,:])\n",
        "  return les_log_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w9EXa8WSck1O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#torch.stack(all_log_X(model,valid,200)).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vl-y3ENoodJk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#torch.stack(all_log_X(model,test,200)).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z_xnY1IC6Qa0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "3e5ae0da-42ca-45d6-bbbf-776d1cc4a2a4"
      },
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[0.5,0.5,0.5],[0.5,0.5,0.5]], dtype=torch.float64)\n",
        "b = torch.tensor([[1,1,1],[0,0,0]], dtype=torch.float64)\n",
        "print(torch.sum(F.binary_cross_entropy(a, b, reduction='none')+0,dim = 1))\n",
        " \n",
        "print(F.binary_cross_entropy(a, b) * 6)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2.0794, 2.0794], dtype=torch.float64)\n",
            "tensor(4.1589, dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4qGn0zsAgkM2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "ecda1b4e-c850-4955-c19e-aa4c45a5a4d7"
      },
      "cell_type": "code",
      "source": [
        "model = Q2_VAE()\n",
        "model = model.to(device)\n",
        "\n",
        "#optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "optimizer = Adam(model.parameters(), lr=3 * 10**(-4))\n",
        "\n",
        "\n",
        "print(model)\n",
        "print(\"\\n\\n# Parameters: \", sum([param.nelement() for param in model.parameters()]))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q2_VAE(\n",
            "  (m): ELU(alpha=1.0)\n",
            "  (conv_e1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (avg_pool_e1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (conv_e2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (avg_pool_e2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (conv_e3): Conv2d(64, 256, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (linear_mean): Linear(in_features=256, out_features=100, bias=True)\n",
            "  (linear_log_var): Linear(in_features=256, out_features=100, bias=True)\n",
            "  (linear_d1): Linear(in_features=100, out_features=256, bias=True)\n",
            "  (conv_d1): Conv2d(256, 64, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4))\n",
            "  (conv_d2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "  (conv_d3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "  (conv_d4): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            ")\n",
            "\n",
            "\n",
            "# Parameters:  938825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BtvyuutNz04O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1797
        },
        "outputId": "318c39e5-081f-48de-a422-56824d9d63be"
      },
      "cell_type": "code",
      "source": [
        "nb_epochs = 20\n",
        "valid_ELBOs = []\n",
        "test_ELBOs = []\n",
        "log_likeli_est_valid = []\n",
        "log_likeli_est_test = []\n",
        "for epoch in range(1, nb_epochs + 1):\n",
        "    train_VAE(epoch, train)\n",
        "    \n",
        "    valid_ELBOs.append(test_VAE(epoch, valid, \"Validation\"))\n",
        "    v_log_like_est= torch.stack(all_log_X(model,valid,200)).mean()\n",
        "    print(\"valid log likelihood estimate: \", v_log_like_est.item())\n",
        "    log_likeli_est_valid.append(v_log_like_est)\n",
        "    \n",
        "    test_ELBOs.append(test_VAE(epoch, test, \"Test\"))\n",
        "    t_log_like_est= torch.stack(all_log_X(model,test,200)).mean()\n",
        "    print(\"test log likelihood estimate: \", t_log_like_est.item())\n",
        "    log_likeli_est_test.append(t_log_like_est)\n",
        "    \n",
        "    \n",
        "    #with torch.no_grad():\n",
        "    #    sample = torch.randn(64, 100).to(device)\n",
        "    #    sample = model.decode(sample).cpu()\n",
        "    #    save_image(sample.view(64, 1, 28, 28),\n",
        "    #                str(epoch) + '.png')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====> Epoch: 1 Train set average ELBO: -188.9227\n",
            "====> Validation set average ELBO: -143.5680\n",
            "valid log likelihood estimate:  -130.0609349931279\n",
            "====> Test set average ELBO: -142.0968\n",
            "test log likelihood estimate:  -128.6616628875085\n",
            "====> Epoch: 2 Train set average ELBO: -128.4978\n",
            "====> Validation set average ELBO: -119.9688\n",
            "valid log likelihood estimate:  -109.41859173938539\n",
            "====> Test set average ELBO: -118.4249\n",
            "test log likelihood estimate:  -108.1382456149142\n",
            "====> Epoch: 3 Train set average ELBO: -113.9364\n",
            "====> Validation set average ELBO: -110.5928\n",
            "valid log likelihood estimate:  -102.07113832260337\n",
            "====> Test set average ELBO: -109.3501\n",
            "test log likelihood estimate:  -100.87480231510914\n",
            "====> Epoch: 4 Train set average ELBO: -107.7312\n",
            "====> Validation set average ELBO: -106.7288\n",
            "valid log likelihood estimate:  -98.65481817337222\n",
            "====> Test set average ELBO: -105.4131\n",
            "test log likelihood estimate:  -97.5641586450368\n",
            "====> Epoch: 5 Train set average ELBO: -104.5327\n",
            "====> Validation set average ELBO: -104.4114\n",
            "valid log likelihood estimate:  -96.80253218677353\n",
            "====> Test set average ELBO: -103.2504\n",
            "test log likelihood estimate:  -95.79352636514403\n",
            "====> Epoch: 6 Train set average ELBO: -102.4636\n",
            "====> Validation set average ELBO: -102.5534\n",
            "valid log likelihood estimate:  -95.13247288953673\n",
            "====> Test set average ELBO: -101.4389\n",
            "test log likelihood estimate:  -94.1708466340263\n",
            "====> Epoch: 7 Train set average ELBO: -100.9919\n",
            "====> Validation set average ELBO: -101.1067\n",
            "valid log likelihood estimate:  -94.04426626883975\n",
            "====> Test set average ELBO: -100.0962\n",
            "test log likelihood estimate:  -93.08986120069062\n",
            "====> Epoch: 8 Train set average ELBO: -99.8054\n",
            "====> Validation set average ELBO: -100.3759\n",
            "valid log likelihood estimate:  -93.13876938823601\n",
            "====> Test set average ELBO: -99.4050\n",
            "test log likelihood estimate:  -92.25919538217249\n",
            "====> Epoch: 9 Train set average ELBO: -98.8603\n",
            "====> Validation set average ELBO: -99.2133\n",
            "valid log likelihood estimate:  -92.6718794368733\n",
            "====> Test set average ELBO: -98.2268\n",
            "test log likelihood estimate:  -91.80895926522676\n",
            "====> Epoch: 10 Train set average ELBO: -98.0579\n",
            "====> Validation set average ELBO: -98.6468\n",
            "valid log likelihood estimate:  -91.96068681231269\n",
            "====> Test set average ELBO: -97.6264\n",
            "test log likelihood estimate:  -91.07897093740496\n",
            "====> Epoch: 11 Train set average ELBO: -97.3999\n",
            "====> Validation set average ELBO: -98.3360\n",
            "valid log likelihood estimate:  -91.58882638788833\n",
            "====> Test set average ELBO: -97.3982\n",
            "test log likelihood estimate:  -90.77954774862854\n",
            "====> Epoch: 12 Train set average ELBO: -96.8170\n",
            "====> Validation set average ELBO: -97.4230\n",
            "valid log likelihood estimate:  -91.04455395064801\n",
            "====> Test set average ELBO: -96.5291\n",
            "test log likelihood estimate:  -90.23922879053052\n",
            "====> Epoch: 13 Train set average ELBO: -96.3080\n",
            "====> Validation set average ELBO: -97.1345\n",
            "valid log likelihood estimate:  -90.65514751522767\n",
            "====> Test set average ELBO: -96.3850\n",
            "test log likelihood estimate:  -89.88584279568391\n",
            "====> Epoch: 14 Train set average ELBO: -95.8557\n",
            "====> Validation set average ELBO: -96.2901\n",
            "valid log likelihood estimate:  -90.30716029435357\n",
            "====> Test set average ELBO: -95.4471\n",
            "test log likelihood estimate:  -89.56262104035154\n",
            "====> Epoch: 15 Train set average ELBO: -95.4635\n",
            "====> Validation set average ELBO: -96.0968\n",
            "valid log likelihood estimate:  -89.99670131567714\n",
            "====> Test set average ELBO: -95.2793\n",
            "test log likelihood estimate:  -89.20438588462311\n",
            "====> Epoch: 16 Train set average ELBO: -95.1318\n",
            "====> Validation set average ELBO: -95.7655\n",
            "valid log likelihood estimate:  -89.75424664306708\n",
            "====> Test set average ELBO: -94.8976\n",
            "test log likelihood estimate:  -89.05170392044644\n",
            "====> Epoch: 17 Train set average ELBO: -94.7503\n",
            "====> Validation set average ELBO: -95.3790\n",
            "valid log likelihood estimate:  -89.46230488789408\n",
            "====> Test set average ELBO: -94.6111\n",
            "test log likelihood estimate:  -88.72597433028025\n",
            "====> Epoch: 18 Train set average ELBO: -94.4936\n",
            "====> Validation set average ELBO: -95.3980\n",
            "valid log likelihood estimate:  -89.25945385708421\n",
            "====> Test set average ELBO: -94.6153\n",
            "test log likelihood estimate:  -88.53959239593958\n",
            "====> Epoch: 19 Train set average ELBO: -94.2136\n",
            "====> Validation set average ELBO: -95.1513\n",
            "valid log likelihood estimate:  -89.1138848561111\n",
            "====> Test set average ELBO: -94.2757\n",
            "test log likelihood estimate:  -88.40012316035137\n",
            "====> Epoch: 20 Train set average ELBO: -93.9149\n",
            "====> Validation set average ELBO: -94.8612\n",
            "valid log likelihood estimate:  -88.88066920154166\n",
            "====> Test set average ELBO: -93.9242\n",
            "test log likelihood estimate:  -88.2041653995502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sqGPi3RP4GNq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "outputId": "7cf84cf1-92fb-4839-fd22-0c7b2e17f57c"
      },
      "cell_type": "code",
      "source": [
        "a.data"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5000, 0.5000, 0.5000],\n",
              "        [0.5000, 0.5000, 0.5000]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "seCAJvYI7FUo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        },
        "outputId": "aba0c5a0-885f-4b82-f686-ebff6381797f"
      },
      "cell_type": "code",
      "source": [
        "a[0,0].item()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "metadata": {
        "id": "Ggh5VlOv7GqK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "b6d40cac-9d74-418f-ce4e-2695eccc09c4"
      },
      "cell_type": "code",
      "source": [
        "\"valid_ELBOs: \", valid_ELBOs"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('valid_ELBOs: ',\n",
              " [-143.5680021484375,\n",
              "  -119.968783984375,\n",
              "  -110.59284765625,\n",
              "  -106.72881821289063,\n",
              "  -104.411356640625,\n",
              "  -102.55339965820312,\n",
              "  -101.10665673828125,\n",
              "  -100.37588842773438,\n",
              "  -99.21325922851562,\n",
              "  -98.6468490234375,\n",
              "  -98.33601171875,\n",
              "  -97.42303930664062,\n",
              "  -97.13451640625,\n",
              "  -96.2900638671875,\n",
              "  -96.09679956054687,\n",
              "  -95.76553125,\n",
              "  -95.3789501953125,\n",
              "  -95.3980119140625,\n",
              "  -95.1512998046875,\n",
              "  -94.86121572265625])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "metadata": {
        "id": "e81VuorULaZV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "88cab7a1-e34c-4a99-f91d-10e7758fe8f0"
      },
      "cell_type": "code",
      "source": [
        "\"test_ELBOs: \", test_ELBOs"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('test_ELBOs: ',\n",
              " [-142.09683178710938,\n",
              "  -118.42489033203125,\n",
              "  -109.35011579589843,\n",
              "  -105.41313127441406,\n",
              "  -103.250404296875,\n",
              "  -101.4388796875,\n",
              "  -100.09616027832031,\n",
              "  -99.40500810546875,\n",
              "  -98.22678623046875,\n",
              "  -97.62643352050782,\n",
              "  -97.39824763183594,\n",
              "  -96.52913178710938,\n",
              "  -96.38504799804687,\n",
              "  -95.44707783203125,\n",
              "  -95.27927751464844,\n",
              "  -94.89763935546875,\n",
              "  -94.61111638183594,\n",
              "  -94.61529077148438,\n",
              "  -94.2757079345703,\n",
              "  -93.92423166503906])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "metadata": {
        "id": "0107riO1PJWS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "ffde3caf-c259-45b9-f611-59438ce34f6a"
      },
      "cell_type": "code",
      "source": [
        "\"log_likeli_est_valid: \", list(torch.stack(log_likeli_est_valid).numpy())"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('log_likeli_est_valid: ',\n",
              " [-130.0609349931279,\n",
              "  -109.41859173938539,\n",
              "  -102.07113832260337,\n",
              "  -98.65481817337222,\n",
              "  -96.80253218677353,\n",
              "  -95.13247288953673,\n",
              "  -94.04426626883975,\n",
              "  -93.13876938823601,\n",
              "  -92.6718794368733,\n",
              "  -91.96068681231269,\n",
              "  -91.58882638788833,\n",
              "  -91.04455395064801,\n",
              "  -90.65514751522767,\n",
              "  -90.30716029435357,\n",
              "  -89.99670131567714,\n",
              "  -89.75424664306708,\n",
              "  -89.46230488789408,\n",
              "  -89.25945385708421,\n",
              "  -89.1138848561111,\n",
              "  -88.88066920154166])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "metadata": {
        "id": "ixpST8XnPMIS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "df0cb7d5-42e4-446e-fe26-69399da933de"
      },
      "cell_type": "code",
      "source": [
        "\"log_likeli_est_test: \", list(torch.stack(log_likeli_est_test).numpy())"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('log_likeli_est_test: ',\n",
              " [-128.6616628875085,\n",
              "  -108.1382456149142,\n",
              "  -100.87480231510914,\n",
              "  -97.5641586450368,\n",
              "  -95.79352636514403,\n",
              "  -94.1708466340263,\n",
              "  -93.08986120069062,\n",
              "  -92.25919538217249,\n",
              "  -91.80895926522676,\n",
              "  -91.07897093740496,\n",
              "  -90.77954774862854,\n",
              "  -90.23922879053052,\n",
              "  -89.88584279568391,\n",
              "  -89.56262104035154,\n",
              "  -89.20438588462311,\n",
              "  -89.05170392044644,\n",
              "  -88.72597433028025,\n",
              "  -88.53959239593958,\n",
              "  -88.40012316035137,\n",
              "  -88.2041653995502])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "metadata": {
        "id": "A1qN24MYRl5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "05850644-7cf6-4728-d828-5643a94b037a"
      },
      "cell_type": "code",
      "source": [
        "-143.5680021484375"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-143.5680021484375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "HMfCDvv9RmUS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}