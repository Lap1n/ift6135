{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assign3_Q2_v7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "7ce_sa4D3EtZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import utils\n",
        "import torch.utils.data as data_utils\n",
        "import torch\n",
        "import os\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from torch.nn.modules import upsampling\n",
        "from torch.functional import F\n",
        "from torch.optim import Adam\n",
        "import math\n",
        "\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "import math\n",
        "\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ueLMu9qF8xIM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# To do this assignment, I did look at this code for the general framework of how to implement VAE and I did copy some code from there:\n",
        "https://github.com/pytorch/examples/blob/master/vae/main.py"
      ]
    },
    {
      "metadata": {
        "id": "rm8up2kW5hzs",
        "colab_type": "code",
        "outputId": "829f77dc-c23d-46b3-cf17-55a9218721ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "cell_type": "code",
      "source": [
        "# If a GPU is available, use it\n",
        "# Pytorch uses an elegant way to keep the code device agnostic\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    use_cuda = True\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    use_cuda = False\n",
        "    \n",
        "print(device)\n",
        "\n",
        "#torch.manual_seed(1) # I may need to fix other seeds"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ung8rzlD3OSl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_data_loader(dataset_location, batch_size):\n",
        "    URL = \"http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/\"\n",
        "    # start processing\n",
        "    def lines_to_np_array(lines):\n",
        "        return np.array([[int(i) for i in line.split()] for line in lines])\n",
        "    splitdata = []\n",
        "    for splitname in [\"train\", \"valid\", \"test\"]:\n",
        "        filename = \"binarized_mnist_%s.amat\" % splitname\n",
        "        filepath = os.path.join(dataset_location, filename)\n",
        "        utils.download_url(URL + filename, dataset_location)\n",
        "        with open(filepath) as f:\n",
        "            lines = f.readlines()\n",
        "        x = lines_to_np_array(lines).astype('float32')\n",
        "        x = x.reshape(x.shape[0], 1, 28, 28)\n",
        "        # pytorch data loader\n",
        "        dataset = data_utils.TensorDataset(torch.from_numpy(x))\n",
        "        print(splitname, len(dataset))\n",
        "        dataset_loader = data_utils.DataLoader(x, batch_size=batch_size, shuffle=splitname == \"train\")\n",
        "        splitdata.append(dataset_loader)\n",
        "    return splitdata"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CaSQVRRi3MaG",
        "colab_type": "code",
        "outputId": "a234c904-905a-4210-a4ca-ced9d79a8ecf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train, valid, test = get_data_loader(\"binarized_mnist\", 64)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/78400000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_train.amat to binarized_mnist/binarized_mnist_train.amat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "78405632it [00:03, 23874664.65it/s]                              \n",
            "  0%|          | 40960/15680000 [00:00<00:41, 379166.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train 50000\n",
            "Downloading http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_valid.amat to binarized_mnist/binarized_mnist_valid.amat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15687680it [00:01, 9274848.23it/s]                              \n",
            "  0%|          | 49152/15680000 [00:00<00:35, 445598.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "valid 10000\n",
            "Downloading http://www.cs.toronto.edu/~larocheh/public/datasets/binarized_mnist/binarized_mnist_test.amat to binarized_mnist/binarized_mnist_test.amat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "15687680it [00:01, 10329388.84it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YjuRoyQ93aGR",
        "colab_type": "code",
        "outputId": "87704aef-0068-4273-c22e-cffb870e26a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "cell_type": "code",
      "source": [
        "print(f\"Your version of Pytorch is {torch.__version__}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your version of Pytorch is 1.0.1.post2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4kghFP-B3gAj",
        "colab_type": "code",
        "outputId": "67ac760a-b2fe-41bf-9ac4-b12515c73685",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "for x in train:\n",
        "    print(x.shape)\n",
        "    plt.imshow(x[0, 0])\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngXMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "nGOBw5ZE3qYC",
        "colab_type": "code",
        "outputId": "c9c20171-d4d3-419e-8a30-1be4aa81870e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "cell_type": "code",
      "source": [
        "print(train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f39ba4478d0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WnR1sTruMEpP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Question 2.1: Train a VAE (10pts)"
      ]
    },
    {
      "metadata": {
        "id": "coXuahzZ26WG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Q2_VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Q2_VAE, self).__init__()\n",
        "        self.m = nn.ELU()\n",
        "        self.conv_e1 = nn.Conv2d(1, 32, (3, 3))\n",
        "        # ELU\n",
        "        self.avg_pool_e1 = nn.AvgPool2d(kernel_size = 2, stride=2)\n",
        "        self.conv_e2 = nn.Conv2d(32, 64, (3, 3))\n",
        "        # ELU\n",
        "        self.avg_pool_e2 = nn.AvgPool2d(kernel_size = 2, stride=2)\n",
        "        self.conv_e3 = nn.Conv2d(64, 256, (5, 5))\n",
        "        # ELU\n",
        "        # Ne pas oublier de mettre en ligne les 256 pour faire une couche de MLP\n",
        "        \n",
        "        self.linear_mean = nn.Linear(256, 100, bias=True)\n",
        "        self.linear_log_var = nn.Linear(256, 100, bias=True)\n",
        "        \n",
        "        self.linear_d1 = nn.Linear(100, 256, bias=True)\n",
        "        # ELU\n",
        "        # Je dois augmenter de deux dimensions(inverse de .view())\n",
        "        self.conv_d1 = nn.Conv2d(256, 64, kernel_size=(5, 5), padding=(4, 4))\n",
        "        # ELU\n",
        "        #self.upsamp_d1 =nn.UpsamplingBilinear2d(scale_factor=2, mode='bilinear')\n",
        "        self.conv_d2 = nn.Conv2d(64, 32, kernel_size=(3, 3), padding=(2, 2))\n",
        "        # ELU\n",
        "        #self.upsamp_d2 =nn.UpsamplingBilinear2d(scale_factor=2, mode='bilinear')\n",
        "        self.conv_d3 = nn.Conv2d(32, 16, kernel_size=(3, 3), padding=(2, 2))\n",
        "        # ELU\n",
        "        self.conv_d4 = nn.Conv2d(16, 1, kernel_size=(3, 3), padding=(2, 2))\n",
        "        \n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.conv_e1(x)\n",
        "        x = self.m(x)\n",
        "        x = self.avg_pool_e1(x)\n",
        "        #print(\"Ici: \", x.shape)\n",
        "        x = self.conv_e2(x)\n",
        "        x = self.m(x)\n",
        "        x = self.avg_pool_e2(x)\n",
        "        x = self.conv_e3(x)\n",
        "        x = self.m(x)\n",
        "        x = x.view(-1, 256) \n",
        "        return self.linear_mean(x), self.linear_log_var(x)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar) + 10**(-7)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "    def decode(self, z):\n",
        "        out = self.linear_d1(z)\n",
        "        out = self.m(out)\n",
        "        out = out.view(-1, 256, 1, 1) # LFPR: J'ai change ca aussi\n",
        "        out = self.conv_d1(out)\n",
        "        out = self.m(out)\n",
        "        #out = self.upsamp_d1(out)\n",
        "        out = F.interpolate(out, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        out = self.conv_d2(out)\n",
        "        out = self.m(out)\n",
        "        #out = self.upsamp_d2(out)\n",
        "        out = F.interpolate(out, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        out = self.conv_d3(out)\n",
        "        out = self.m(out)\n",
        "        return self.conv_d4(out)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        #mu, logvar = self.encode(x.view(-1, 784))\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xueR_J-S7_H8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Reconstruction + KL divergence losses summed over all elements and batch\n",
        "# We return the negative of the ELBO for gradient descent\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    \n",
        "    N_BCE=-torch.sum(F.binary_cross_entropy(torch.sigmoid(recon_x.view(-1, 784)\\\n",
        "                          ), x.view(-1, 784), reduction='none'),dim=1).mean()\n",
        "    \n",
        "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD = 0.5*torch.sum(-1 - logvar + mu.pow(2) + logvar.exp(), dim = 1).mean()\n",
        "\n",
        "    #return BCE + KLD\n",
        "    return - (N_BCE - KLD)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_VAE(epoch,loader):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    #for batch_idx, (data, _) in enumerate(loader):\n",
        "    for batch_idx, data in enumerate(loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        loss = loss_function(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        #if batch_idx % 100 == 0:\n",
        "        #    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t average ELBO: {:.6f}'.format(\n",
        "        #        epoch, batch_idx * len(data), len(loader.dataset),\n",
        "        #        100. * batch_idx / len(loader),\n",
        "        #        - batch_size * loss.item() / len(data)))\n",
        "        \n",
        "    average_ELBO = - train_loss * batch_size / len(loader.dataset)\n",
        "    print('====> Epoch: {} Train set average ELBO: {:.4f}'.format(\n",
        "          epoch, average_ELBO))\n",
        "    return average_ELBO\n",
        "\n",
        "\n",
        "def test_VAE(epoch, loader, state = \"Validation\"):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        #for i, (data, _) in enumerate(loader):\n",
        "        for i, data in enumerate(loader):\n",
        "            data = data.to(device)\n",
        "            recon_batch, mu, logvar = model(data)\n",
        "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
        "            #if i == 0:\n",
        "            #    n = min(data.size(0), 8)\n",
        "            #    comparison = torch.cat([data[:n],\n",
        "            #                            recon_batch.view(batch_size, 1, 28, 28)[:n]])\n",
        "            #    save_image(comparison.cpu(),\n",
        "            #                str(epoch) + '.png', nrow=n)\n",
        "    \n",
        "    test_loss /= (len(loader.dataset)/ batch_size)\n",
        "    average_ELBO = - test_loss\n",
        "    print('====> ' + state +' set average ELBO: {:.4f}'.format(average_ELBO))\n",
        "    return average_ELBO\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qM0-aEfYZ6DI",
        "colab_type": "code",
        "outputId": "e8618aac-910a-4fb4-d46a-0a817eef0cdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "cell_type": "code",
      "source": [
        "len(train.dataset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "IWgQ_CEQZ-mJ",
        "colab_type": "code",
        "outputId": "57b105b2-f881-4aaf-ba54-86df4f61f33a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        }
      },
      "cell_type": "code",
      "source": [
        "model = Q2_VAE()\n",
        "model = model.to(device)\n",
        "\n",
        "#optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "optimizer = Adam(model.parameters(), lr=3 * 10**(-4))\n",
        "\n",
        "print(model)\n",
        "print(\"\\n\\n# Parameters: \", sum([param.nelement() for param in model.parameters()]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q2_VAE(\n",
            "  (m): ELU(alpha=1.0)\n",
            "  (conv_e1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (avg_pool_e1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (conv_e2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (avg_pool_e2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (conv_e3): Conv2d(64, 256, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (linear_mean): Linear(in_features=256, out_features=100, bias=True)\n",
            "  (linear_log_var): Linear(in_features=256, out_features=100, bias=True)\n",
            "  (linear_d1): Linear(in_features=100, out_features=256, bias=True)\n",
            "  (conv_d1): Conv2d(256, 64, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4))\n",
            "  (conv_d2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "  (conv_d3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "  (conv_d4): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            ")\n",
            "\n",
            "\n",
            "# Parameters:  938825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NrM2xuFyZ-vS",
        "colab_type": "code",
        "outputId": "084e280d-b6f2-4616-d0d3-ac740d02dfd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 876
        }
      },
      "cell_type": "code",
      "source": [
        "nb_epochs = 20\n",
        "for epoch in range(1, nb_epochs + 1):\n",
        "    train_VAE(epoch, train)\n",
        "    test_VAE(epoch, valid)\n",
        "with torch.no_grad():\n",
        "    sample = torch.randn(64, 100).to(device)\n",
        "    sample = model.decode(sample).cpu()\n",
        "    save_image(sample.view(64, 1, 28, 28),\n",
        "                str(epoch) + '.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====> Epoch: 1 Train set average ELBO: -182.2706\n",
            "====> Validation set average ELBO: -137.3361\n",
            "====> Epoch: 2 Train set average ELBO: -124.6678\n",
            "====> Validation set average ELBO: -117.8182\n",
            "====> Epoch: 3 Train set average ELBO: -112.1374\n",
            "====> Validation set average ELBO: -110.0154\n",
            "====> Epoch: 4 Train set average ELBO: -107.3396\n",
            "====> Validation set average ELBO: -106.3443\n",
            "====> Epoch: 5 Train set average ELBO: -104.4111\n",
            "====> Validation set average ELBO: -104.0974\n",
            "====> Epoch: 6 Train set average ELBO: -102.3293\n",
            "====> Validation set average ELBO: -102.0641\n",
            "====> Epoch: 7 Train set average ELBO: -100.8243\n",
            "====> Validation set average ELBO: -101.0259\n",
            "====> Epoch: 8 Train set average ELBO: -99.6585\n",
            "====> Validation set average ELBO: -100.0452\n",
            "====> Epoch: 9 Train set average ELBO: -98.7667\n",
            "====> Validation set average ELBO: -99.0009\n",
            "====> Epoch: 10 Train set average ELBO: -98.0199\n",
            "====> Validation set average ELBO: -98.5278\n",
            "====> Epoch: 11 Train set average ELBO: -97.2981\n",
            "====> Validation set average ELBO: -97.7497\n",
            "====> Epoch: 12 Train set average ELBO: -96.7091\n",
            "====> Validation set average ELBO: -97.6286\n",
            "====> Epoch: 13 Train set average ELBO: -96.3258\n",
            "====> Validation set average ELBO: -96.9575\n",
            "====> Epoch: 14 Train set average ELBO: -95.8360\n",
            "====> Validation set average ELBO: -96.4233\n",
            "====> Epoch: 15 Train set average ELBO: -95.3735\n",
            "====> Validation set average ELBO: -96.0844\n",
            "====> Epoch: 16 Train set average ELBO: -95.0206\n",
            "====> Validation set average ELBO: -95.6550\n",
            "====> Epoch: 17 Train set average ELBO: -94.7092\n",
            "====> Validation set average ELBO: -95.4846\n",
            "====> Epoch: 18 Train set average ELBO: -94.4579\n",
            "====> Validation set average ELBO: -94.9379\n",
            "====> Epoch: 19 Train set average ELBO: -94.1467\n",
            "====> Validation set average ELBO: -95.0183\n",
            "====> Epoch: 20 Train set average ELBO: -93.8983\n",
            "====> Validation set average ELBO: -94.7597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DK0YUfHDNPTJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**As can be seen in the previous cell, we obtain an ELBO bigger than -96 on the validation set after 20 epochs.**"
      ]
    },
    {
      "metadata": {
        "id": "GMQeQS1bMQqq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Question 2.2: Evaluating log-likelihood with Variational Autoencoders (20 pts)"
      ]
    },
    {
      "metadata": {
        "id": "mobnEBqDMYOK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 2.2.1**"
      ]
    },
    {
      "metadata": {
        "id": "N_2Pldyd58XT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def copy_tensor_K_times(tensor, K):\n",
        "  return torch.stack([tensor.clone() for _ in range(K)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uxJjrSgr8lWl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reconstruction(multi_x,z_x,model):\n",
        "  recon_x = model.decode(z_x)\n",
        "  return - torch.sum(F.binary_cross_entropy(torch.sigmoid(recon_x.view(-1, 784)), multi_x.view(-1, 784), reduction='none'),dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4lQ7fIE064UB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def log_gaussian_standard(z):\n",
        "  # no more terms because mu = 0 and sigma = 1\n",
        "  K = z.shape[1]\n",
        "  pi_term = - (K/2) * torch.log(torch.tensor(2 * math.pi))\n",
        "  return torch.sum(- z**2/2, dim = 1) + pi_term"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V7QDQLKk8WGV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def log_gaussian_density(z_x, multi_x, model):\n",
        "  mu, logvar = model.encode(multi_x)\n",
        "  K = z_x.shape[1]\n",
        "  pi_term = - (K/2) * torch.log(torch.tensor(2 * math.pi))\n",
        "  # We add 10**(-7) to avoid taking the log of 0 if logvar is very negative\n",
        "  return torch.sum(-(z_x - mu)**2/(2*torch.exp(logvar)+ 10**(-7)) - torch.log(torch.exp(0.5*logvar) + 10**(-7)), dim = 1) + pi_term"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S-DTHCpiMNHY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def importance_sampling(model, X, Z):\n",
        "  X = X.view((-1,1,28,28))\n",
        "  model.eval()\n",
        "  log_probs = []\n",
        "  with torch.no_grad():\n",
        "    for pos, x in enumerate(X):\n",
        "      z_x = Z[pos]\n",
        "      multi_x = copy_tensor_K_times(x, Z.shape[1]) \n",
        "      log_p_x_z = reconstruction(multi_x,z_x,model)\n",
        "      log_p_z = log_gaussian_standard(z_x)\n",
        "      log_q_z_x = log_gaussian_density(z_x, multi_x, model)\n",
        "      w =log_p_x_z + log_p_z - log_q_z_x\n",
        "      m = torch.max(w)\n",
        "      value = - torch.log(torch.tensor(Z.shape[1],dtype=torch.float64)) + m + torch.log(torch.sum(torch.exp(w-m)))\n",
        "      log_probs.append(value)\n",
        "  return log_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CnXmdniv11Ir",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Question 2.2.2**"
      ]
    },
    {
      "metadata": {
        "id": "oL4jqlpnMXev",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def all_log_X(model,loader,K):\n",
        "  model.eval()\n",
        "  les_log_probs = []\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, data in enumerate(loader):\n",
        "      data = data.to(device)\n",
        "      for x in data:\n",
        "        multi_x = copy_tensor_K_times(x, K)\n",
        "        mu, log_var = model.encode(multi_x)\n",
        "        z = model.reparameterize(mu, log_var)\n",
        "        les_log_probs += importance_sampling(model, x.view((1,784)), z[None, : ,:])\n",
        "  return les_log_probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4qGn0zsAgkM2",
        "colab_type": "code",
        "outputId": "5b60f5bf-1b75-476e-8613-d5b283fb925d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "cell_type": "code",
      "source": [
        "model = Q2_VAE()\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = Adam(model.parameters(), lr=3 * 10**(-4))\n",
        "\n",
        "print(model)\n",
        "print(\"\\n\\n# Parameters: \", sum([param.nelement() for param in model.parameters()]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Q2_VAE(\n",
            "  (m): ELU(alpha=1.0)\n",
            "  (conv_e1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (avg_pool_e1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (conv_e2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (avg_pool_e2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (conv_e3): Conv2d(64, 256, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (linear_mean): Linear(in_features=256, out_features=100, bias=True)\n",
            "  (linear_log_var): Linear(in_features=256, out_features=100, bias=True)\n",
            "  (linear_d1): Linear(in_features=100, out_features=256, bias=True)\n",
            "  (conv_d1): Conv2d(256, 64, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4))\n",
            "  (conv_d2): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "  (conv_d3): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "  (conv_d4): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            ")\n",
            "\n",
            "\n",
            "# Parameters:  938825\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BtvyuutNz04O",
        "colab_type": "code",
        "outputId": "58745435-90fa-45e1-c8f1-0d7d0f3d7745",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1128
        }
      },
      "cell_type": "code",
      "source": [
        "nb_epochs = 20\n",
        "valid_ELBOs = []\n",
        "test_ELBOs = []\n",
        "log_likeli_est_valid = []\n",
        "log_likeli_est_test = []\n",
        "for epoch in range(1, nb_epochs + 1):\n",
        "    train_VAE(epoch, train)\n",
        "    test_VAE(epoch, valid, \"Validation\")\n",
        "    test_VAE(epoch, test, \"Test\")\n",
        "    \n",
        "    #with torch.no_grad():\n",
        "    #    sample = torch.randn(64, 100).to(device)\n",
        "    #    sample = model.decode(sample).cpu()\n",
        "    #    save_image(sample.view(64, 1, 28, 28),\n",
        "    #                str(epoch) + '.png')\n",
        "    \n",
        "v_log_like_est= torch.stack(all_log_X(model,valid,200)).mean()\n",
        "print(\"valid log likelihood estimate: \", v_log_like_est.item())\n",
        "\n",
        "t_log_like_est= torch.stack(all_log_X(model,test,200)).mean()\n",
        "print(\"test log likelihood estimate: \", t_log_like_est.item())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====> Epoch: 1 Train set average ELBO: -179.5255\n",
            "====> Validation set average ELBO: -137.1342\n",
            "====> Test set average ELBO: -135.8453\n",
            "====> Epoch: 2 Train set average ELBO: -124.9550\n",
            "====> Validation set average ELBO: -117.7417\n",
            "====> Test set average ELBO: -116.3942\n",
            "====> Epoch: 3 Train set average ELBO: -112.5014\n",
            "====> Validation set average ELBO: -110.2641\n",
            "====> Test set average ELBO: -109.0000\n",
            "====> Epoch: 4 Train set average ELBO: -106.9975\n",
            "====> Validation set average ELBO: -106.1850\n",
            "====> Test set average ELBO: -104.9958\n",
            "====> Epoch: 5 Train set average ELBO: -104.1800\n",
            "====> Validation set average ELBO: -103.6721\n",
            "====> Test set average ELBO: -102.4390\n",
            "====> Epoch: 6 Train set average ELBO: -102.1364\n",
            "====> Validation set average ELBO: -101.7952\n",
            "====> Test set average ELBO: -100.7761\n",
            "====> Epoch: 7 Train set average ELBO: -100.7264\n",
            "====> Validation set average ELBO: -101.1857\n",
            "====> Test set average ELBO: -100.0746\n",
            "====> Epoch: 8 Train set average ELBO: -99.5386\n",
            "====> Validation set average ELBO: -99.8506\n",
            "====> Test set average ELBO: -98.8698\n",
            "====> Epoch: 9 Train set average ELBO: -98.6915\n",
            "====> Validation set average ELBO: -99.0248\n",
            "====> Test set average ELBO: -98.0717\n",
            "====> Epoch: 10 Train set average ELBO: -97.9206\n",
            "====> Validation set average ELBO: -98.4736\n",
            "====> Test set average ELBO: -97.6371\n",
            "====> Epoch: 11 Train set average ELBO: -97.3222\n",
            "====> Validation set average ELBO: -97.7064\n",
            "====> Test set average ELBO: -96.7827\n",
            "====> Epoch: 12 Train set average ELBO: -96.7397\n",
            "====> Validation set average ELBO: -97.4471\n",
            "====> Test set average ELBO: -96.5815\n",
            "====> Epoch: 13 Train set average ELBO: -96.2443\n",
            "====> Validation set average ELBO: -97.0171\n",
            "====> Test set average ELBO: -96.1624\n",
            "====> Epoch: 14 Train set average ELBO: -95.9211\n",
            "====> Validation set average ELBO: -96.6116\n",
            "====> Test set average ELBO: -95.8621\n",
            "====> Epoch: 15 Train set average ELBO: -95.4592\n",
            "====> Validation set average ELBO: -96.4280\n",
            "====> Test set average ELBO: -95.7773\n",
            "====> Epoch: 16 Train set average ELBO: -95.1992\n",
            "====> Validation set average ELBO: -96.0585\n",
            "====> Test set average ELBO: -95.1844\n",
            "====> Epoch: 17 Train set average ELBO: -94.8293\n",
            "====> Validation set average ELBO: -95.9876\n",
            "====> Test set average ELBO: -95.0994\n",
            "====> Epoch: 18 Train set average ELBO: -94.5628\n",
            "====> Validation set average ELBO: -95.2803\n",
            "====> Test set average ELBO: -94.6178\n",
            "====> Epoch: 19 Train set average ELBO: -94.3492\n",
            "====> Validation set average ELBO: -95.0371\n",
            "====> Test set average ELBO: -94.1706\n",
            "====> Epoch: 20 Train set average ELBO: -94.0601\n",
            "====> Validation set average ELBO: -94.7713\n",
            "====> Test set average ELBO: -94.0951\n",
            "valid log likelihood estimate:  -88.88284499816541\n",
            "test log likelihood estimate:  -88.2384369109548\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wI9QyaWhf9vJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**As can be seen in the results above, after training the model with 20 epochs, we obtain:**\n",
        "\n",
        "- **the ELBO on the validation set  is given by -94.7713**\n",
        "\n",
        "- **the ELBO on the test set  is given by -94.0951**\n",
        "\n",
        "- **the log-likelihood  estimate  on the validation set is given by -88.8828**\n",
        "\n",
        "- **the log-likelihood  estimate  on the test set is given by -88.2384**\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "L4Lj7wcNN7pa",
        "colab_type": "code",
        "outputId": "ddcaef57-37d6-4ceb-9eeb-118c0d42b542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        }
      },
      "cell_type": "code",
      "source": [
        "# This is just to verify that the method importance_sampling(model, X, Z)\n",
        "# accepts:\n",
        "#\n",
        "# a model \n",
        "# An (M,D) array of xi’s\n",
        "# An (M,K,L) array of zik’s\n",
        "#\n",
        "# returns\n",
        "# (logp(x1),...,logp(xM)) estimates of size (M,)\n",
        "\n",
        "K = 200\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  for batch_idx, data in enumerate(train):\n",
        "    data = data.to(device)\n",
        "    count = 0\n",
        "    les_x = []\n",
        "    les_z = []\n",
        "    for x in data:\n",
        "      count+=1\n",
        "      multi_x = copy_tensor_K_times(x, K)\n",
        "      mu, log_var = model.encode(multi_x)\n",
        "      z = model.reparameterize(mu, log_var)\n",
        "      les_x.append(x.view((784)))\n",
        "      #les_z.append(z[: ,:])\n",
        "      les_z.append(z)\n",
        "      if count == 5:\n",
        "        les_x = torch.stack(les_x)\n",
        "        les_z = torch.stack(les_z)\n",
        "        break\n",
        "    break\n",
        "print(torch.stack(importance_sampling(model,les_x,les_z)).detach().numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-106.71257132 -141.75741144  -79.3507142  -105.34865897  -87.11534383]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}